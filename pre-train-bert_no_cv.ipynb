{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": false,
    "id": "e6qg-tZRAs5o",
    "outputId": "ed86966e-300a-4c0b-f87c-cff04957f545"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    BertForPreTraining,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset\n",
    "import random\n",
    "import evaluate\n",
    "import logging\n",
    "import torch\n",
    "import nltk\n",
    "from datasets import Dataset, DatasetDict\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": false,
    "id": "DyfV8PPXYZv2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7cc3c4b99a47c28d94830d4bd7b63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "BLOCK_SIZE = 256  # Maximum number of tokens in an input sample\n",
    "NSP_PROB = 0.50  # Probability that the next sentence is the actual next sentence in NSP ##=> Segun BERT\n",
    "MAX_LENGTH = 512  # Maximum number of tokens in an input sample after padding\n",
    "SHORT_SEQ_PROB = 0.1  # Probability of generating shorter sequences to minimize the mismatch between pretraining and fine-tuning.\n",
    "MLM_PROB = 0.15  # Probability with which tokens are masked in MLM ##=> BERTimbau 0.15\n",
    "\n",
    "# Entrenaniento\n",
    "TRAIN_BATCH_SIZE = 128  # Batch-size for pretraining the model on ##=> BERTimbau base 128\n",
    "EVAL_BATCH_SIZE = 128\n",
    "MAX_EPOCHS = 40  # Maximum number of epochs to train the model for\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "# Early stopping\n",
    "ES_PATIENCE = 3\n",
    "ES_THRESHOLD = 0.001\n",
    "\n",
    "PATH_DATASET = \"unsupervised.csv\"\n",
    "PATH_RESULT_MODEL = \"/vol/model\"\n",
    "\n",
    "# Modelo\n",
    "# Name of pretrained model from ðŸ¤— Model Hub\n",
    "MODEL_CHECKPOINT = \"neuralmind/bert-base-portuguese-cased\"\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": false,
    "id": "NI-mBfl0Away"
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_model(model_name=\"neuralmind/bert-base-portuguese-cased\", num_unfrozen_layers=4):\n",
    "    # Load pre-trained model and tokenizer\n",
    "    model = BertForPreTraining.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": false,
    "id": "WdfJeWkVA0Xy"
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_train_features(examples, tokenizer):\n",
    "\n",
    "    #######\n",
    "    # NSP\n",
    "    # We define the maximum number of tokens after tokenization that each training sample\n",
    "    # will have\n",
    "    max_num_tokens = BLOCK_SIZE - \\\n",
    "        tokenizer.num_special_tokens_to_add(pair=True)\n",
    "\n",
    "    \"\"\"Function to prepare features for NSP task\n",
    "\n",
    "    Arguments:\n",
    "      examples: A dictionary with 1 key (\"text\")\n",
    "        text: List of raw documents (str)\n",
    "    Returns:\n",
    "      examples:  A dictionary with 4 keys\n",
    "        input_ids: List of tokenized, concatnated, and batched\n",
    "          sentences from the individual raw documents (int)\n",
    "        token_type_ids: List of integers (0 or 1) corresponding\n",
    "          to: 0 for senetence no. 1 and padding, 1 for sentence\n",
    "          no. 2\n",
    "        attention_mask: List of integers (0 or 1) corresponding\n",
    "          to: 1 for non-padded tokens, 0 for padded\n",
    "        next_sentence_label: List of integers (0 or 1) corresponding\n",
    "          to: 1 if the second sentence actually follows the first,\n",
    "          0 if the senetence is sampled from somewhere else in the corpus\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove un-wanted samples from the training set\n",
    "    examples[\"document\"] = [\n",
    "        d.strip() for d in examples[\"text\"] if len(d) > 0\n",
    "    ]\n",
    "    # Split the documents from the dataset into it's individual sentences\n",
    "    examples[\"sentences\"] = [\n",
    "        nltk.tokenize.sent_tokenize(document) for document in examples[\"document\"]\n",
    "    ]\n",
    "    # Convert the tokens into ids using the trained tokenizer\n",
    "    examples[\"tokenized_sentences\"] = [\n",
    "        [tokenizer.convert_tokens_to_ids(\n",
    "            tokenizer.tokenize(sent)) for sent in doc]\n",
    "        for doc in examples[\"sentences\"]\n",
    "    ]\n",
    "\n",
    "    # Define the outputs\n",
    "    examples[\"input_ids\"] = []\n",
    "    examples[\"token_type_ids\"] = []\n",
    "    examples[\"attention_mask\"] = []\n",
    "    examples[\"next_sentence_label\"] = []\n",
    "\n",
    "    for doc_index, document in enumerate(examples[\"tokenized_sentences\"]):\n",
    "\n",
    "        current_chunk = []  # a buffer stored current working segments\n",
    "        current_length = 0\n",
    "        i = 0\n",
    "\n",
    "        # We *usually* want to fill up the entire sequence since we are padding\n",
    "        # to `block_size` anyways, so short sequences are generally wasted\n",
    "        # computation. However, we *sometimes*\n",
    "        # (i.e., short_seq_prob == 0.1 == 10% of the time) want to use shorter\n",
    "        # sequences to minimize the mismatch between pretraining and fine-tuning.\n",
    "        # The `target_seq_length` is just a rough target however, whereas\n",
    "        # `block_size` is a hard limit.\n",
    "        target_seq_length = max_num_tokens\n",
    "\n",
    "        # If your sentences are very long, you might want to adjust these:\n",
    "        # Increase minimum length for \"short\" sequences\n",
    "        target_seq_length = random.randint(2, max_num_tokens)\n",
    "        \n",
    "        while i < len(document):\n",
    "            segment = document[i]\n",
    "            current_chunk.append(segment)\n",
    "            current_length += len(segment)\n",
    "            if i == len(document) - 1 or current_length >= target_seq_length:\n",
    "                if current_chunk:\n",
    "                    # `a_end` is how many segments from `current_chunk` go into the `A`\n",
    "                    # (first) sentence.\n",
    "                    a_end = 1\n",
    "                    if len(current_chunk) >= 2:\n",
    "                        a_end = random.randint(1, len(current_chunk) - 1)\n",
    "\n",
    "                    tokens_a = []\n",
    "                    for j in range(a_end):\n",
    "                        tokens_a.extend(current_chunk[j])\n",
    "\n",
    "                    tokens_b = []\n",
    "\n",
    "                    if len(current_chunk) == 1 or random.random() < NSP_PROB:\n",
    "                        is_random_next = True\n",
    "                        target_b_length = target_seq_length - len(tokens_a)\n",
    "\n",
    "                        # This should rarely go for more than one iteration for large\n",
    "                        # corpora. However, just to be careful, we try to make sure that\n",
    "                        # the random document is not the same as the document\n",
    "                        # we're processing.\n",
    "                        for _ in range(10):\n",
    "                            random_document_index = random.randint(\n",
    "                                0, len(examples[\"tokenized_sentences\"]) - 1\n",
    "                            )\n",
    "                            if random_document_index != doc_index:\n",
    "                                break\n",
    "\n",
    "                        random_document = examples[\"tokenized_sentences\"][\n",
    "                            random_document_index\n",
    "                        ]\n",
    "                        random_start = random.randint(\n",
    "                            0, len(random_document) - 1)\n",
    "                        for j in range(random_start, len(random_document)):\n",
    "                            tokens_b.extend(random_document[j])\n",
    "                            if len(tokens_b) >= target_b_length:\n",
    "                                break\n",
    "                        # We didn't actually use these segments so we \"put them back\" so\n",
    "                        # they don't go to waste.\n",
    "                        num_unused_segments = len(current_chunk) - a_end\n",
    "                        i -= num_unused_segments\n",
    "                    else:\n",
    "                        is_random_next = False\n",
    "                        for j in range(a_end, len(current_chunk)):\n",
    "                            tokens_b.extend(current_chunk[j])\n",
    "\n",
    "                    # Controlar que los tokens no exedan 512\n",
    "                    if len(tokens_a) > max_num_tokens:\n",
    "                        tokens_a = tokens_a[0:max_num_tokens]\n",
    "                    if len(tokens_b) > max_num_tokens:\n",
    "                        tokens_b = tokens_b[0:max_num_tokens]\n",
    "\n",
    "                    input_ids = tokenizer.build_inputs_with_special_tokens(\n",
    "                        tokens_a, tokens_b\n",
    "                    )\n",
    "                    # add token type ids, 0 for sentence a, 1 for sentence b\n",
    "                    token_type_ids = tokenizer.create_token_type_ids_from_sequences(\n",
    "                        tokens_a, tokens_b\n",
    "                    )\n",
    "\n",
    "                    padded = tokenizer.pad(\n",
    "                        {\"input_ids\": input_ids, \"token_type_ids\": token_type_ids},\n",
    "                        padding=\"max_length\",\n",
    "                        max_length=MAX_LENGTH,\n",
    "                    )\n",
    "\n",
    "                    examples[\"input_ids\"].append(padded[\"input_ids\"])\n",
    "                    examples[\"token_type_ids\"].append(padded[\"token_type_ids\"])\n",
    "                    examples[\"attention_mask\"].append(padded[\"attention_mask\"])\n",
    "                    examples[\"next_sentence_label\"].append(\n",
    "                        1 if is_random_next else 0)\n",
    "                    current_chunk = []\n",
    "                    current_length = 0\n",
    "            i += 1\n",
    "\n",
    "    # We delete all the un-necessary columns from our dataset\n",
    "    del examples[\"document\"]\n",
    "    del examples[\"sentences\"]\n",
    "    del examples[\"text\"]\n",
    "    del examples[\"tokenized_sentences\"]\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "b698f590c64b41f5a1dd4c0a08693cd1",
      "6191df7925414c9487360ee6e862359c",
      "f018480dca854a648dff942ed9db4ee3",
      "ee6e0ab0c5d74b6d8110162aba877ea6",
      "f675e3a8f6d449a086068819e6e92986",
      "fcf20ef2bfd84174844cfc693709e729",
      "39b58d56c9fb43f5962d3bfecb648766",
      "a31b8ccfd53048c0ae38e090cfbcad78",
      "541b9f0cc1ad4a9e99152a3de4245971",
      "9642a250b24f400d8e950a7431d8fdc5",
      "8feb7982963342f1b3bac9950a199b00"
     ]
    },
    "editable": false,
    "id": "HG81D2lbCsQ_",
    "outputId": "c2c97874-3d8c-4779-98c5-d2efcd6dedc4"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(tokenizer, csv_path=\"unsupervised.csv\"):\n",
    "    # Load dataset from CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "    # Create DataFrame with only the 'text' column\n",
    "    x = df['text'].copy()\n",
    "\n",
    "    # Create train/validation split (80/20)\n",
    "    x_train, x_validation = train_test_split(x, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "    # Reset indices\n",
    "    x_train = x_train.reset_index(drop=True)\n",
    "    x_validation = x_validation.reset_index(drop=True)\n",
    "\n",
    "    # Convert to datasets\n",
    "    train_dataset = Dataset.from_pandas(pd.DataFrame(x_train, columns=['text']))\n",
    "    validation_dataset = Dataset.from_pandas(pd.DataFrame(x_validation, columns=['text']))\n",
    "\n",
    "    # Create DatasetDict\n",
    "    dataset_dict = DatasetDict({'train': train_dataset, 'validation': validation_dataset})\n",
    "\n",
    "    # Tokenize dataset\n",
    "    tokenized_dataset = dataset_dict.map(\n",
    "        lambda examples: prepare_train_features(examples, tokenizer),\n",
    "        batched=True,\n",
    "        remove_columns=dataset_dict[\"train\"].column_names,\n",
    "        num_proc=12\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Dataset prepared with NSP features. Using text from {csv_path}\")\n",
    "    return tokenized_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": false,
    "id": "LIFjCCV_VMlk"
   },
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    mlm_logits = logits[0]\n",
    "    nsp_logits = logits[1]\n",
    "    return mlm_logits.argmax(-1), nsp_logits.argmax(-1)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    mlm_preds = preds[0]\n",
    "    nsp_preds = preds[1]\n",
    "\n",
    "    mlm_labels = labels[0]\n",
    "    nsp_labels = labels[1]\n",
    "\n",
    "    mask = mlm_labels != -100\n",
    "    mlm_labels = mlm_labels[mask]\n",
    "    mlm_preds = mlm_preds[mask]\n",
    "\n",
    "    mlm_accuracy = metric.compute(\n",
    "        predictions=mlm_preds, references=mlm_labels)[\"accuracy\"]\n",
    "    nsp_accuracy = metric.compute(\n",
    "        predictions=nsp_preds, references=nsp_labels)[\"accuracy\"]\n",
    "\n",
    "    return {\"Masked ML Accuracy\": mlm_accuracy, \"NSP Accuracy\": nsp_accuracy}\n",
    "\n",
    "\n",
    "def plot_losses(trainer):\n",
    "    log_history = trainer.state.log_history\n",
    "    df_history = pd.DataFrame(log_history)\n",
    "    set_train_loss = []\n",
    "    set_val_loss = []\n",
    "    epochs = int(df_history['epoch'].max())\n",
    "    for i in range(1, epochs+1):\n",
    "        index_val = df_history.loc[(\n",
    "            df_history['epoch'] == i), 'loss'].index.tolist()[0]\n",
    "        index_train = index_val-1\n",
    "        train_loss = df_history.loc[index_train, 'loss']\n",
    "        val_loss = df_history.loc[index_val, 'eval_loss']\n",
    "        set_train_loss.append(train_loss)\n",
    "        set_val_loss.append(val_loss)\n",
    "\n",
    "    # Plot\n",
    "    loss_index = range(1, len(set_train_loss) + 1)\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(loss_index, set_train_loss, label='Train loss')\n",
    "    plt.plot(loss_index, set_val_loss, label='Val loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(range(1, len(set_train_loss) + 1))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "f55c0afa874c46618d16591edc94efa8",
      "0c54411b592244708711515f3be5987f",
      "f229590e1c83477987a952b13137f01c",
      "6df265e0210d49a288337bf784880dd2",
      "6ac966fe50ec4cbcb25606ce99b436a1",
      "f1c6f0e43e204021b79035332e483fc8",
      "f389db0554dd40e8a12474cbf2499003",
      "7887783911b34034a3216dc598512ab5",
      "c30d446a43ed4566b823c9993ac42b9a",
      "a4718b1501dc40619453ca968f8ea86d",
      "11a17996326a40ea9de2350a72576ac8",
      "51c42b5c14804b54b6cbf08d3a54bec4",
      "d36af92611bf4be8b86e400f8a1f730f",
      "b095296f2f39449897c9e12531197b7b",
      "24ecc09e351e4e17986a75c4fc724292",
      "0431da823a294721a9daf50bfd76a987",
      "bcbd90f81cc54d3a8dcfbfd702ec1a27",
      "da8ebaf21ff44a11a9b0c6e1a8f3fe40",
      "085a6f8fa3be4bea8f3c7ebab97aa479",
      "f31c42f174144ee691187ea1a99bbb35",
      "bbc3828f9e1045928cf6d77b5fade272",
      "ed1e8fe043664beb8cdc9d8397b5a642"
     ]
    },
    "editable": false,
    "id": "Z-lggelPVM6i",
    "outputId": "e1549a8a-1347-49cf-fd0b-31009928e606"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ddc94476244740a2c5074b375bf9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f2761b808547d2964cac42cb73c7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc1137a53644490b7fe983161d487e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f401515b2fa54828aec3c86905c80c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9518bfb5145347c1931c69a26c2d71a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44841e9161064a3e9656b8d8d82ab7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466847b64fb3492790a1c30cc1ab13cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=12):   0%|          | 0/15006 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acd103d1e6b42a7807fdc2904665b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=12):   0%|          | 0/3752 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dataset prepared with NSP features. Using text from unsupervised.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and tokenizer\n",
    "model, tokenizer = load_and_prepare_model()\n",
    "\n",
    "# Prepare dataset\n",
    "tokenized_dataset = prepare_dataset(tokenizer, csv_path='unsupervised.csv')\n",
    "\n",
    "# Initialize data collator with NSP\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=MLM_PROB\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": false,
    "id": "ckNKtTyDWKLb",
    "outputId": "90c00fd4-2542-4b11-e957-fa0e23bdcd29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label'],\n",
       "        num_rows: 15006\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label'],\n",
       "        num_rows: 3752\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": false,
    "id": "qS1nGCc2dUOq"
   },
   "outputs": [],
   "source": [
    "learning_rates = [\n",
    "    1e-5,\n",
    "    1e-6\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "WARNING:accelerate.utils.other:Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training..., LR = 0.0003\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='4720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  18/4720 00:10 < 49:32, 1.58 it/s, Epoch 0.14/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training..., LR = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearning_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m plot_losses(trainer)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/transformers/trainer.py:2486\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2487\u001b[0m ):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for learning_rate in learning_rates:\n",
    "  # Calculate steps (same as before)\n",
    "  total_train_samples = len(tokenized_dataset[\"train\"])\n",
    "  num_update_steps_per_epoch = total_train_samples // TRAIN_BATCH_SIZE\n",
    "  total_training_steps = num_update_steps_per_epoch * MAX_EPOCHS\n",
    "  warmup_steps = total_training_steps // 10\n",
    "  # Initialize Trainer\n",
    "  training_args = TrainingArguments(\n",
    "        output_dir=PATH_RESULT_MODEL,\n",
    "        logging_first_step=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "        per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
    "        logging_steps=100,\n",
    "        bf16=True,\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=MAX_EPOCHS,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        # Add these parameters\n",
    "        warmup_steps=warmup_steps,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        )\n",
    "\n",
    "  early_stop = EarlyStoppingCallback(early_stopping_patience = ES_PATIENCE, early_stopping_threshold = ES_THRESHOLD)\n",
    "  model, tokenizer = load_and_prepare_model()\n",
    "  trainer = Trainer(\n",
    "      model=model,\n",
    "      args=training_args,\n",
    "      train_dataset=tokenized_dataset['train'],\n",
    "      eval_dataset=tokenized_dataset['validation'],\n",
    "      data_collator=data_collator,\n",
    "      compute_metrics=compute_metrics,\n",
    "      preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "      callbacks=[early_stop]\n",
    "  )\n",
    "\n",
    "  # Start training\n",
    "  print(f\"Starting training..., LR = {learning_rate}\")\n",
    "  trainer.train()\n",
    "  plot_losses(trainer)\n",
    "  # Save the model\n",
    "  model.save_pretrained(f\"{PATH_RESULT_MODEL}/final_model_{learning_rate}\")\n",
    "  tokenizer.save_pretrained(f\"{PATH_RESULT_MODEL}/final_model_{learning_rate}\")\n",
    "  logger.info(\"Training completed and model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6135391,
     "sourceId": 9972436,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0431da823a294721a9daf50bfd76a987": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "085a6f8fa3be4bea8f3c7ebab97aa479": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c54411b592244708711515f3be5987f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1c6f0e43e204021b79035332e483fc8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f389db0554dd40e8a12474cbf2499003",
      "value": "Mapâ€‡(num_proc=12):â€‡100%"
     }
    },
    "11a17996326a40ea9de2350a72576ac8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24ecc09e351e4e17986a75c4fc724292": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbc3828f9e1045928cf6d77b5fade272",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ed1e8fe043664beb8cdc9d8397b5a642",
      "value": "â€‡1230/1230â€‡[00:06&lt;00:00,â€‡189.58â€‡examples/s]"
     }
    },
    "39b58d56c9fb43f5962d3bfecb648766": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51c42b5c14804b54b6cbf08d3a54bec4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d36af92611bf4be8b86e400f8a1f730f",
       "IPY_MODEL_b095296f2f39449897c9e12531197b7b",
       "IPY_MODEL_24ecc09e351e4e17986a75c4fc724292"
      ],
      "layout": "IPY_MODEL_0431da823a294721a9daf50bfd76a987"
     }
    },
    "541b9f0cc1ad4a9e99152a3de4245971": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6191df7925414c9487360ee6e862359c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcf20ef2bfd84174844cfc693709e729",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_39b58d56c9fb43f5962d3bfecb648766",
      "value": "Downloadingâ€‡builderâ€‡script:â€‡100%"
     }
    },
    "6ac966fe50ec4cbcb25606ce99b436a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6df265e0210d49a288337bf784880dd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4718b1501dc40619453ca968f8ea86d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_11a17996326a40ea9de2350a72576ac8",
      "value": "â€‡4916/4916â€‡[00:29&lt;00:00,â€‡292.19â€‡examples/s]"
     }
    },
    "7887783911b34034a3216dc598512ab5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8feb7982963342f1b3bac9950a199b00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9642a250b24f400d8e950a7431d8fdc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a31b8ccfd53048c0ae38e090cfbcad78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4718b1501dc40619453ca968f8ea86d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b095296f2f39449897c9e12531197b7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_085a6f8fa3be4bea8f3c7ebab97aa479",
      "max": 1230,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f31c42f174144ee691187ea1a99bbb35",
      "value": 1230
     }
    },
    "b698f590c64b41f5a1dd4c0a08693cd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6191df7925414c9487360ee6e862359c",
       "IPY_MODEL_f018480dca854a648dff942ed9db4ee3",
       "IPY_MODEL_ee6e0ab0c5d74b6d8110162aba877ea6"
      ],
      "layout": "IPY_MODEL_f675e3a8f6d449a086068819e6e92986"
     }
    },
    "bbc3828f9e1045928cf6d77b5fade272": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcbd90f81cc54d3a8dcfbfd702ec1a27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c30d446a43ed4566b823c9993ac42b9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d36af92611bf4be8b86e400f8a1f730f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcbd90f81cc54d3a8dcfbfd702ec1a27",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_da8ebaf21ff44a11a9b0c6e1a8f3fe40",
      "value": "Mapâ€‡(num_proc=12):â€‡100%"
     }
    },
    "da8ebaf21ff44a11a9b0c6e1a8f3fe40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed1e8fe043664beb8cdc9d8397b5a642": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee6e0ab0c5d74b6d8110162aba877ea6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9642a250b24f400d8e950a7431d8fdc5",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8feb7982963342f1b3bac9950a199b00",
      "value": "â€‡4.20k/4.20kâ€‡[00:00&lt;00:00,â€‡88.7kB/s]"
     }
    },
    "f018480dca854a648dff942ed9db4ee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a31b8ccfd53048c0ae38e090cfbcad78",
      "max": 4203,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_541b9f0cc1ad4a9e99152a3de4245971",
      "value": 4203
     }
    },
    "f1c6f0e43e204021b79035332e483fc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f229590e1c83477987a952b13137f01c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7887783911b34034a3216dc598512ab5",
      "max": 4916,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c30d446a43ed4566b823c9993ac42b9a",
      "value": 4916
     }
    },
    "f31c42f174144ee691187ea1a99bbb35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f389db0554dd40e8a12474cbf2499003": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f55c0afa874c46618d16591edc94efa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0c54411b592244708711515f3be5987f",
       "IPY_MODEL_f229590e1c83477987a952b13137f01c",
       "IPY_MODEL_6df265e0210d49a288337bf784880dd2"
      ],
      "layout": "IPY_MODEL_6ac966fe50ec4cbcb25606ce99b436a1"
     }
    },
    "f675e3a8f6d449a086068819e6e92986": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcf20ef2bfd84174844cfc693709e729": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
